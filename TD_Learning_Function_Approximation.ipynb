{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gym\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from estimator import Estimator\n",
    "from value_estimator import ValueEstimator\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(s):\n",
    "    split = s.split(',')\n",
    "    n = np.zeros(len(split))\n",
    "    for i in range(len(split)):\n",
    "        n[i] = float(split[i])\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = 1268140\n",
    "with open(\"demonstrations_10k\") as f:\n",
    "    s_arr = np.zeros((11, num_observations))\n",
    "    r_arr = np.zeros((1, num_observations))\n",
    "    a_arr = np.zeros((3, num_observations))\n",
    "    sprime_arr = np.zeros((11, num_observations))\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for l in f:\n",
    "        if len(l.strip().split(';')) <= 1:\n",
    "            continue\n",
    "    \n",
    "        i += 1\n",
    "        s, r, a, sp = l.strip().split(';')\n",
    "        s_arr[:,i] = parse(s)\n",
    "        r_arr[:,i] = parse(r)\n",
    "        a_arr[:,i] = parse(a)\n",
    "        sprime_arr[:, i] = parse(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_arr = np.swapaxes(s_arr, 0, 1)\n",
    "r_arr = np.swapaxes(r_arr, 0, 1)\n",
    "a_arr = np.swapaxes(a_arr, 0, 1)\n",
    "sprime_arr = np.swapaxes(sprime_arr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('rbf1', RBFSampler(gamma=5.0, n_components=100, random_state=None)), ('rbf2', RBFSampler(gamma=2.0, n_components=100, random_state=None)), ('rbf3', RBFSampler(gamma=1.0, n_components=100, random_state=None)), ('rbf4', RBFSampler(gamma=0.5, n_components=100, random_state=None))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Preprocessing: Normalize to zero mean and unit variance\n",
    "# We use a few samples from the observation space to do this\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(s_arr)\n",
    "\n",
    "# Used to convert a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(s_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator():\n",
    "    \"\"\"\n",
    "    Value Function approximator. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scaler, featurizer):\n",
    "        self.model = SGDRegressor(learning_rate=\"constant\")\n",
    "        # We need to call partial_fit once to initialize the model\n",
    "        # or we get a NotFittedError when trying to make a prediction\n",
    "        # This is quite hacky.\n",
    "        self.scaler = scaler\n",
    "        self.featurizer = featurizer\n",
    "        self.model.partial_fit([self.featurize_state(s_arr[0,:])], [0])\n",
    "    \n",
    "    def featurize_state(self, state):\n",
    "        \"\"\"\n",
    "        Returns the featurized representation for a state.\n",
    "        \"\"\"\n",
    "        scaled = self.scaler.transform([state])\n",
    "        featurized = self.featurizer.transform(scaled)\n",
    "        return featurized[0]\n",
    "    \n",
    "    def predict(self, s):\n",
    "        \"\"\"\n",
    "        Makes value function predictions.\n",
    "        \"\"\"\n",
    "        features = self.featurize_state(s)\n",
    "        return self.model.predict([features])[0]\n",
    "    \n",
    "    def update(self, s, y):\n",
    "        \"\"\"\n",
    "        Updates the estimator parameters for a given state and action towards\n",
    "        the target y.\n",
    "        \"\"\"\n",
    "        features = self.featurize_state(s)\n",
    "        self.model.partial_fit([features], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_learning(estimator, num_episodes, discount_factor=0.95):\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        pkl_name = 'estimator%d.pkl' % episode\n",
    "        sys.stdout.flush()\n",
    "        for i in itertools.count():\n",
    "            if i >= s_arr.shape[0]:\n",
    "                break\n",
    "            state = s_arr[i,:]\n",
    "            reward = r_arr[i,:]\n",
    "            # action not needed for incremental update when we are only learning value function!\n",
    "            # we have no idea how states transition or how to choose a good state action pair\n",
    "            # but that's ok :) \n",
    "            action = a_arr[i,:]\n",
    "            next_state = sprime_arr[i,:]\n",
    "            \n",
    "            # TD Update\n",
    "            q_value_next = estimator.predict(next_state)\n",
    "            \n",
    "            td_target = reward + discount_factor * q_value_next\n",
    "            \n",
    "            # Update the function approximator using our target\n",
    "            estimator.update(state, td_target)\n",
    "            \n",
    "            print(\"\\rStep {} @ Episode {}/{}\".format(i, episode + 1, num_episodes), end=\"\")\n",
    "        \n",
    "        with open(pkl_name, 'wb') as pkl:\n",
    "            pickle.dump(estimator, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(scaler, featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1268139 @ Episode 30/30"
     ]
    }
   ],
   "source": [
    "stats = td_learning(estimator, 30, discount_factor=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('estimator_final.pkl', 'wb') as pkl:\n",
    "    pickle.dump(estimator, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('estimator_final.pkl', 'wb') as pkl:\n",
    "    pickle.dump(estimator, pkl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
