{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gym\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from estimator import Estimator\n",
    "from value_estimator import ValueEstimator\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "matplotlib.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(s):\n",
    "    split = s.split(',')\n",
    "    n = np.zeros(len(split))\n",
    "    for i in range(len(split)):\n",
    "        n[i] = float(split[i])\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = 1268140\n",
    "with open(\"demonstrations_10k\") as f:\n",
    "    s_arr = np.zeros((num_observations, 11))\n",
    "    r_arr = np.zeros((num_observations, 1))\n",
    "    a_arr = np.zeros((num_observations, 3))\n",
    "    sprime_arr = np.zeros((num_observations, 11))\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for l in f:\n",
    "        if len(l.strip().split(';')) <= 1:\n",
    "            continue\n",
    "    \n",
    "        i += 1\n",
    "        s, r, a, sp = l.strip().split(';')\n",
    "        s_arr[i, :] = parse(s)\n",
    "        r_arr[i, :] = parse(r)\n",
    "        a_arr[i, :] = parse(a)\n",
    "        sprime_arr[i, :] = parse(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Preprocessing: Normalize to zero mean and unit variance\n",
    "# We use a few samples from the observation space to do this\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(s_arr)\n",
    "\n",
    "# Used to convert a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(s_arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
